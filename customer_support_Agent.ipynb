{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pRl95XlM1sSG",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "%pip install crewai chromadb crewai[tools]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "os.environ[\"OPENAI_API_KEY\"] = \"xx\""
      ],
      "metadata": {
        "id": "-VRcookoiAEg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import os\n",
        "import numpy as np\n",
        "from typing import Dict, Any, List\n",
        "from crewai import Agent, Task, Crew, Process, LLM\n",
        "from crewai.tools import BaseTool\n",
        "from pydantic import BaseModel, Field\n",
        "import logging\n",
        "from openai import OpenAI\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "logging.basicConfig(level=logging.INFO)\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "# Sample database for order status\n",
        "ORDERS_DB = {\n",
        "    \"ABC-123\": {\"status\": \"shipped\", \"tracking\": \"1Z999AA1234567890\", \"estimated_delivery\": \"2024-01-15\"},\n",
        "    \"DEF-456\": {\"status\": \"processing\", \"estimated_ship\": \"2024-01-12\"},\n",
        "    \"GHI-789\": {\"status\": \"delivered\", \"delivered_date\": \"2024-01-10\"}\n",
        "}\n",
        "\n",
        "# Sample Knowledge base for policies with embeddings\n",
        "KNOWLEDGE_BASE = {\n",
        "    \"return_policy\": \"\"\"\n",
        "    Our return policy allows returns within 30 days of purchase.\n",
        "    Items must be in original condition with tags attached.\n",
        "    Refunds are processed within 5-7 business days.\n",
        "    Original receipt or order confirmation required.\n",
        "    \"\"\",\n",
        "    \"shipping_info\": \"\"\"\n",
        "    Standard shipping: 5-7 business days\n",
        "    Express shipping: 2-3 business days\n",
        "    Free shipping on orders over $50\n",
        "    International shipping available to most countries\n",
        "    Tracking information provided via email\n",
        "    \"\"\",\n",
        "    \"warranty_info\": \"\"\"\n",
        "    All products come with a 1-year manufacturer warranty.\n",
        "    Extended warranty options available at checkout.\n",
        "    Warranty covers manufacturing defects but not normal wear.\n",
        "    Contact customer service for warranty claims.\n",
        "    \"\"\"\n",
        "}\n",
        "\n",
        "client = OpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"))\n",
        "\n",
        "class VectorKnowledgeBase:\n",
        "    def __init__(self):\n",
        "        self.documents = []\n",
        "        self.embeddings = []\n",
        "        self.metadata = []\n",
        "        self._initialize_knowledge_base()\n",
        "\n",
        "    def _get_embedding(self, text: str) -> List[float]:\n",
        "        try:\n",
        "            response = client.embeddings.create(\n",
        "                input=text,\n",
        "                model=\"text-embedding-3-small\"\n",
        "            )\n",
        "            return response.data[0].embedding\n",
        "        except Exception as e:\n",
        "            logger.error(f\"Error generating embedding: {e}\")\n",
        "            return [0.0] * 1536\n",
        "\n",
        "    def _initialize_knowledge_base(self):\n",
        "        logger.info(\"Initializing vector knowledge base...\")\n",
        "\n",
        "        for policy_name, content in KNOWLEDGE_BASE.items():\n",
        "            self.documents.append(content)\n",
        "\n",
        "            embedding = self._get_embedding(content)\n",
        "            self.embeddings.append(embedding)\n",
        "\n",
        "            self.metadata.append({\n",
        "                \"policy_name\": policy_name,\n",
        "                \"policy_type\": policy_name.replace('_', ' ').title(),\n",
        "                \"content_length\": len(content)\n",
        "            })\n",
        "\n",
        "        self.embeddings = np.array(self.embeddings)\n",
        "        logger.info(f\"Knowledge base initialized with {len(self.documents)} documents\")\n",
        "\n",
        "    def search(self, query: str, top_k: int = 3, threshold: float = 0.7) -> List[Dict]:\n",
        "        \"\"\"Perform semantic search using vector similarity\"\"\"\n",
        "        logger.info(f\"Performing vector search for: {query}\")\n",
        "\n",
        "        query_embedding = np.array(self._get_embedding(query)).reshape(1, -1)\n",
        "\n",
        "        # Calculate cosine similarities\n",
        "        similarities = cosine_similarity(query_embedding, self.embeddings)[0]\n",
        "\n",
        "        results = []\n",
        "        for i, similarity in enumerate(similarities):\n",
        "            if similarity >= threshold:\n",
        "                results.append({\n",
        "                    \"content\": self.documents[i],\n",
        "                    \"metadata\": self.metadata[i],\n",
        "                    \"similarity_score\": float(similarity),\n",
        "                    \"index\": i\n",
        "                })\n",
        "\n",
        "        results.sort(key=lambda x: x[\"similarity_score\"], reverse=True)\n",
        "        return results[:top_k]\n",
        "\n",
        "vector_kb = VectorKnowledgeBase()\n",
        "\n",
        "# Tool 1: Order Status Tool\n",
        "class OrderStatusInput(BaseModel):\n",
        "    order_id: str = Field(..., description=\"The order ID to look up\")\n",
        "\n",
        "class OrderStatusTool(BaseTool):\n",
        "    name: str = \"order_status_lookup\"\n",
        "    description: str = \"Look up the status of an order by order ID\"\n",
        "    args_schema: type[BaseModel] = OrderStatusInput\n",
        "\n",
        "    def _run(self, order_id: str) -> str:\n",
        "        logger.info(f\"Looking up order status for: {order_id}\")\n",
        "\n",
        "        if order_id in ORDERS_DB:\n",
        "            order_info = ORDERS_DB[order_id]\n",
        "            return json.dumps(order_info, indent=2)\n",
        "        else:\n",
        "            return f\"Order {order_id} not found in our system.\"\n",
        "\n",
        "# Tool 2: Knowledge Base Tool\n",
        "class VectorKnowledgeBaseInput(BaseModel):\n",
        "    query: str = Field(..., description=\"The policy or information query for semantic search\")\n",
        "\n",
        "class VectorKnowledgeBaseTool(BaseTool):\n",
        "    name: str = \"vector_knowledge_search\"\n",
        "    description: str = \"Search company policies using semantic vector search (return policy, shipping, warranty)\"\n",
        "    args_schema: type[BaseModel] = VectorKnowledgeBaseInput\n",
        "\n",
        "    def _run(self, query: str) -> str:\n",
        "        logger.info(f\"Performing vector search for: {query}\")\n",
        "\n",
        "        results = vector_kb.search(query, top_k=3, threshold=0.6)\n",
        "\n",
        "        if not results:\n",
        "            return \"No relevant policy information found for your query.\"\n",
        "\n",
        "        formatted_results = []\n",
        "        for result in results:\n",
        "            policy_type = result[\"metadata\"][\"policy_type\"]\n",
        "            content = result[\"content\"].strip()\n",
        "            similarity = result[\"similarity_score\"]\n",
        "\n",
        "            formatted_results.append(\n",
        "                f\"**{policy_type}** (Relevance: {similarity:.2f})\\n{content}\"\n",
        "            )\n",
        "\n",
        "        return \"\\n\\n\" + \"=\"*50 + \"\\n\\n\".join(formatted_results)\n",
        "\n",
        "# Tool 3: Chat Tool\n",
        "class GeneralChatInput(BaseModel):\n",
        "    message: str = Field(..., description=\"The user's message for general conversation\")\n",
        "\n",
        "class GeneralChatTool(BaseTool):\n",
        "    name: str = \"general_chat\"\n",
        "    description: str = \"Handle general conversation and greetings\"\n",
        "    args_schema: type[BaseModel] = GeneralChatInput\n",
        "\n",
        "    def _run(self, message: str) -> str:\n",
        "        logger.info(f\"Handling general chat: {message}\")\n",
        "        return f\"Hello! I understand you said: '{message}'. How can I help you with your order or questions about our policies today?\"\n",
        "\n",
        "# Define Agent\n",
        "def create_customer_support_agent():\n",
        "\n",
        "    order_tool = OrderStatusTool()\n",
        "    knowledge_tool = VectorKnowledgeBaseTool()\n",
        "    chat_tool = GeneralChatTool()\n",
        "\n",
        "    support_agent = Agent(\n",
        "        role=\"Customer Support Specialist\",\n",
        "        goal=\"\"\"Provide excellent customer support by:\n",
        "        1. Analyzing user queries to determine the appropriate tool\n",
        "        2. Using order_status_lookup for order-related questions (format: XXX-123)\n",
        "        3. Using vector_knowledge_search for policy questions with semantic understanding\n",
        "        4. Using general_chat for greetings and casual conversation\n",
        "        5. Always being helpful and professional\"\"\",\n",
        "\n",
        "        backstory=\"\"\"You are an experienced customer support agent for an e-commerce store.\n",
        "        You have access to order tracking systems, an advanced semantic search knowledge base,\n",
        "        and can engage in friendly conversation. You excel at understanding customer intent\n",
        "        and routing their requests to the appropriate tools.\"\"\",\n",
        "\n",
        "        tools=[order_tool, knowledge_tool, chat_tool],\n",
        "        verbose=True,\n",
        "        llm=LLM(model=\"gpt-4o-mini\"),\n",
        "        max_iter=3,\n",
        "        allow_delegation=False\n",
        "    )\n",
        "\n",
        "    return support_agent\n",
        "\n",
        "# Task creation\n",
        "def create_support_task(user_query: str):\n",
        "    \"\"\"Create a task that demonstrates tool selection reasoning\"\"\"\n",
        "\n",
        "    return Task(\n",
        "        description=f\"\"\"\n",
        "        Analyze this customer query and provide appropriate assistance: \"{user_query}\"\n",
        "\n",
        "        Follow this decision process:\n",
        "        1. If the query mentions an order ID (format: XXX-123), use order_status_lookup\n",
        "        2. If the query asks about policies (return, shipping, warranty), use vector_knowledge_search\n",
        "        3. If the query is a greeting or general conversation, use general_chat\n",
        "        4. Always explain your reasoning for tool selection\n",
        "        5. Provide a complete, helpful response with similarity scores when using vector search\n",
        "\n",
        "        Query: {user_query}\n",
        "        \"\"\",\n",
        "\n",
        "        expected_output=\"\"\"A complete response that includes:\n",
        "        - Explanation of which tool was selected and why\n",
        "        - The relevant information retrieved (with similarity scores for vector search)\n",
        "        - A helpful, professional response to the customer\"\"\",\n",
        "\n",
        "        agent=create_customer_support_agent()\n",
        "    )\n",
        "\n",
        "def demonstrate_agent(queries: List[str]):\n",
        "\n",
        "    print(\"Customer Support Agent\")\n",
        "    print(\"=\" * 60)\n",
        "\n",
        "    for i, query in enumerate(queries, 1):\n",
        "        print(f\"\\n Test Case {i}: {query}\")\n",
        "        print(\"-\" * 40)\n",
        "\n",
        "        task = create_support_task(query)\n",
        "\n",
        "        crew = Crew(\n",
        "            agents=[task.agent],\n",
        "            tasks=[task],\n",
        "            process=Process.sequential,\n",
        "            verbose=True\n",
        "        )\n",
        "        try:\n",
        "            result = crew.kickoff()\n",
        "            print(f\"✅ Response: {result}\")\n",
        "        except Exception as e:\n",
        "            print(f\"❌ Error: {e}\")\n",
        "\n",
        "        print(\"\\n\" + \"=\"*60)\n",
        "\n",
        "# Testing\n",
        "if __name__ == \"__main__\":\n",
        "\n",
        "    test_queries = [\n",
        "        \"Where is my order #ABC-123?\",  # Tests Order Status Tool\n",
        "        \"What is your return policy?\",   # Tests Vector Knowledge Search\n",
        "        \"Hello, how are you?\",          # Tests General Chat\n",
        "    ]\n",
        "\n",
        "    demonstrate_agent(test_queries)"
      ],
      "metadata": {
        "id": "-SwBWb8AcEn0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "NdpeD3YFuUyA"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}